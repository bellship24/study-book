{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from feast import FeatureStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>conv_rate</th>\n",
       "      <th>acc_rate</th>\n",
       "      <th>avg_daily_trips</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-31 15:00:00+00:00</td>\n",
       "      <td>1005</td>\n",
       "      <td>0.115611</td>\n",
       "      <td>0.554137</td>\n",
       "      <td>318</td>\n",
       "      <td>2023-04-15 15:00:47.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-31 16:00:00+00:00</td>\n",
       "      <td>1005</td>\n",
       "      <td>0.863201</td>\n",
       "      <td>0.755645</td>\n",
       "      <td>386</td>\n",
       "      <td>2023-04-15 15:00:47.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-31 17:00:00+00:00</td>\n",
       "      <td>1005</td>\n",
       "      <td>0.310922</td>\n",
       "      <td>0.456694</td>\n",
       "      <td>924</td>\n",
       "      <td>2023-04-15 15:00:47.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-31 18:00:00+00:00</td>\n",
       "      <td>1005</td>\n",
       "      <td>0.518537</td>\n",
       "      <td>0.884248</td>\n",
       "      <td>989</td>\n",
       "      <td>2023-04-15 15:00:47.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-31 19:00:00+00:00</td>\n",
       "      <td>1005</td>\n",
       "      <td>0.745835</td>\n",
       "      <td>0.864634</td>\n",
       "      <td>272</td>\n",
       "      <td>2023-04-15 15:00:47.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>2023-04-15 13:00:00+00:00</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.575827</td>\n",
       "      <td>0.753413</td>\n",
       "      <td>358</td>\n",
       "      <td>2023-04-15 15:00:47.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>2023-04-15 14:00:00+00:00</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.755292</td>\n",
       "      <td>0.665238</td>\n",
       "      <td>164</td>\n",
       "      <td>2023-04-15 15:00:47.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>2021-04-12 07:00:00+00:00</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.511466</td>\n",
       "      <td>0.254260</td>\n",
       "      <td>233</td>\n",
       "      <td>2023-04-15 15:00:47.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>2023-04-08 03:00:00+00:00</td>\n",
       "      <td>1003</td>\n",
       "      <td>0.189217</td>\n",
       "      <td>0.900712</td>\n",
       "      <td>881</td>\n",
       "      <td>2023-04-15 15:00:47.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>2023-04-08 03:00:00+00:00</td>\n",
       "      <td>1003</td>\n",
       "      <td>0.189217</td>\n",
       "      <td>0.900712</td>\n",
       "      <td>881</td>\n",
       "      <td>2023-04-15 15:00:47.216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1807 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               event_timestamp  driver_id  conv_rate  acc_rate  \\\n",
       "0    2023-03-31 15:00:00+00:00       1005   0.115611  0.554137   \n",
       "1    2023-03-31 16:00:00+00:00       1005   0.863201  0.755645   \n",
       "2    2023-03-31 17:00:00+00:00       1005   0.310922  0.456694   \n",
       "3    2023-03-31 18:00:00+00:00       1005   0.518537  0.884248   \n",
       "4    2023-03-31 19:00:00+00:00       1005   0.745835  0.864634   \n",
       "...                        ...        ...        ...       ...   \n",
       "1802 2023-04-15 13:00:00+00:00       1001   0.575827  0.753413   \n",
       "1803 2023-04-15 14:00:00+00:00       1001   0.755292  0.665238   \n",
       "1804 2021-04-12 07:00:00+00:00       1001   0.511466  0.254260   \n",
       "1805 2023-04-08 03:00:00+00:00       1003   0.189217  0.900712   \n",
       "1806 2023-04-08 03:00:00+00:00       1003   0.189217  0.900712   \n",
       "\n",
       "      avg_daily_trips                 created  \n",
       "0                 318 2023-04-15 15:00:47.216  \n",
       "1                 386 2023-04-15 15:00:47.216  \n",
       "2                 924 2023-04-15 15:00:47.216  \n",
       "3                 989 2023-04-15 15:00:47.216  \n",
       "4                 272 2023-04-15 15:00:47.216  \n",
       "...               ...                     ...  \n",
       "1802              358 2023-04-15 15:00:47.216  \n",
       "1803              164 2023-04-15 15:00:47.216  \n",
       "1804              233 2023-04-15 15:00:47.216  \n",
       "1805              881 2023-04-15 15:00:47.216  \n",
       "1806              881 2023-04-15 15:00:47.216  \n",
       "\n",
       "[1807 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(\"data/driver_stats.parquet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# register feature definitions and deploy feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jb/.pyenv/versions/dt-feast-py3-11-3/lib/python3.11/site-packages/feast/feature_store.py:561: RuntimeWarning: On demand feature view is an experimental feature. This API is stable, but the functionality does not scale well for offline retrieval\n",
      "  warnings.warn(\n",
      "\u001b[1m\u001b[94mNo changes to registry\n",
      "\u001b[1m\u001b[94mNo changes to infrastructure\n"
     ]
    }
   ],
   "source": [
    "! feast apply"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate training data or power batch scoring models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Feature schema -----\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 10 columns):\n",
      " #   Column                              Non-Null Count  Dtype              \n",
      "---  ------                              --------------  -----              \n",
      " 0   driver_id                           3 non-null      int64              \n",
      " 1   event_timestamp                     3 non-null      datetime64[ns, UTC]\n",
      " 2   label_driver_reported_satisfaction  3 non-null      int64              \n",
      " 3   val_to_add                          3 non-null      int64              \n",
      " 4   val_to_add_2                        3 non-null      int64              \n",
      " 5   conv_rate                           3 non-null      float32            \n",
      " 6   acc_rate                            3 non-null      float32            \n",
      " 7   avg_daily_trips                     3 non-null      int32              \n",
      " 8   conv_rate_plus_val1                 3 non-null      float64            \n",
      " 9   conv_rate_plus_val2                 3 non-null      float64            \n",
      "dtypes: datetime64[ns, UTC](1), float32(2), float64(2), int32(1), int64(4)\n",
      "memory usage: 336.0 bytes\n",
      "None\n",
      "\n",
      "----- Example features -----\n",
      "   driver_id           event_timestamp  label_driver_reported_satisfaction  \\\n",
      "0       1001 2021-04-12 10:59:42+00:00                                   1   \n",
      "1       1002 2021-04-12 08:12:10+00:00                                   5   \n",
      "2       1003 2021-04-12 16:40:26+00:00                                   3   \n",
      "\n",
      "   val_to_add  val_to_add_2  conv_rate  acc_rate  avg_daily_trips  \\\n",
      "0           1            10   0.511466  0.254260              233   \n",
      "1           2            20   0.132074  0.011565              245   \n",
      "2           3            30   0.736346  0.622294              678   \n",
      "\n",
      "   conv_rate_plus_val1  conv_rate_plus_val2  \n",
      "0             1.511466            10.511466  \n",
      "1             2.132074            20.132074  \n",
      "2             3.736346            30.736346  \n"
     ]
    }
   ],
   "source": [
    "entity_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"driver_id\": [1001, 1002, 1003,],\n",
    "        \"event_timestamp\": [\n",
    "            datetime(2021, 4, 12, 10, 59, 42),\n",
    "            datetime(2021, 4, 12, 8, 12, 10),\n",
    "            datetime(2021, 4, 12, 16, 40, 26),\n",
    "        ],\n",
    "        \"label_driver_reported_satisfaction\": [1, 5, 3],\n",
    "        \"val_to_add\": [1, 2, 3],\n",
    "        \"val_to_add_2\": [10, 20, 30],\n",
    "    }\n",
    ")\n",
    "\n",
    "store = FeatureStore(repo_path=\".\")\n",
    "\n",
    "training_df = store.get_historical_features(\n",
    "    entity_df=entity_df,\n",
    "    features=[\n",
    "        \"driver_hourly_stats:conv_rate\",\n",
    "        \"driver_hourly_stats:acc_rate\",\n",
    "        \"driver_hourly_stats:avg_daily_trips\",\n",
    "        \"transformed_conv_rate:conv_rate_plus_val1\",\n",
    "        \"transformed_conv_rate:conv_rate_plus_val2\",\n",
    "    ],\n",
    ").to_df()\n",
    "\n",
    "print(\"----- Feature schema -----\", end=\"\\n\")\n",
    "print(training_df.info())\n",
    "\n",
    "print()\n",
    "print(\"----- Example features -----\", end=\"\\n\")\n",
    "print(training_df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run offline inference (batch scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Example features -----\n",
      "   driver_id                  event_timestamp  \\\n",
      "0       1001 2023-04-15 06:48:48.884403+00:00   \n",
      "1       1002 2023-04-15 06:48:48.884403+00:00   \n",
      "2       1003 2023-04-15 06:48:48.884403+00:00   \n",
      "\n",
      "   label_driver_reported_satisfaction  val_to_add  val_to_add_2  conv_rate  \\\n",
      "0                                   1           1            10   0.805241   \n",
      "1                                   5           2            20   0.093653   \n",
      "2                                   3           3            30   0.896571   \n",
      "\n",
      "   acc_rate  avg_daily_trips  conv_rate_plus_val1  conv_rate_plus_val2  \n",
      "0  0.683805               51             1.805241            10.805241  \n",
      "1  0.008572              398             2.093653            20.093653  \n",
      "2  0.487203              601             3.896571            30.896571  \n"
     ]
    }
   ],
   "source": [
    "entity_df[\"event_timestamp\"] = pd.to_datetime(\"now\", utc=True)\n",
    "training_df = store.get_historical_features(\n",
    "    entity_df=entity_df,\n",
    "    features=[\n",
    "        \"driver_hourly_stats:conv_rate\",\n",
    "        \"driver_hourly_stats:acc_rate\",\n",
    "        \"driver_hourly_stats:avg_daily_trips\",\n",
    "        \"transformed_conv_rate:conv_rate_plus_val1\",\n",
    "        \"transformed_conv_rate:conv_rate_plus_val2\",\n",
    "    ],\n",
    ").to_df()\n",
    "\n",
    "print()\n",
    "print(\"----- Example features -----\", end=\"\\n\")\n",
    "print(training_df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ingest batch features into online store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materializing \u001b[1m\u001b[32m2\u001b[0m feature views to \u001b[1m\u001b[32m2023-04-15 17:11:13+09:00\u001b[0m into the \u001b[1m\u001b[32msqlite\u001b[0m online store.\n",
      "\n",
      "\u001b[1m\u001b[32mdriver_hourly_stats_fresh\u001b[0m from \u001b[1m\u001b[32m2023-04-15 16:37:55+09:00\u001b[0m to \u001b[1m\u001b[32m2023-04-15 17:11:13+09:00\u001b[0m:\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 1295.34it/s]\n",
      "\u001b[1m\u001b[32mdriver_hourly_stats\u001b[0m from \u001b[1m\u001b[32m2023-04-15 16:37:55+09:00\u001b[0m to \u001b[1m\u001b[32m2023-04-15 17:11:13+09:00\u001b[0m:\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 4324.92it/s]\n"
     ]
    }
   ],
   "source": [
    "! CURRENT_TIME=$(date -u +\"%Y-%m-%dT%H:%M:%S\") && \\\n",
    "  feast materialize-incremental $CURRENT_TIME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fetch feature vectors for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc_rate': [0.9208038449287415, 0.05192827060818672],\n",
      " 'avg_daily_trips': [115, 598],\n",
      " 'conv_rate': [0.318071186542511, 0.8333941102027893],\n",
      " 'driver_id': [1004, 1005]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from feast import FeatureStore\n",
    "\n",
    "store = FeatureStore(repo_path=\".\")\n",
    "\n",
    "feature_vector = store.get_online_features(\n",
    "    features=[\n",
    "        \"driver_hourly_stats:conv_rate\",\n",
    "        \"driver_hourly_stats:acc_rate\",\n",
    "        \"driver_hourly_stats:avg_daily_trips\",\n",
    "    ],\n",
    "    entity_rows=[\n",
    "        # {join_key: entity_value}\n",
    "        {\"driver_id\": 1004},\n",
    "        {\"driver_id\": 1005},\n",
    "    ],\n",
    ").to_dict()\n",
    "\n",
    "pprint(feature_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use feature service to fetch online features instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2733840029.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from feast import FeatureService driver_stats_fs = FeatureService(\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from feast import FeatureService\n",
    "driver_stats_fs = FeatureService(\n",
    "    name=\"driver_activity_v1\",\n",
    "    features=[driver_hourly_stats_view],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RequestDataNotFoundInEntityRowsException",
     "evalue": "Required request data source features ['val_to_add', 'val_to_add_2'] not found in the entity rows, but required by feature views",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRequestDataNotFoundInEntityRowsException\u001b[0m  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m feature_store \u001b[39m=\u001b[39m FeatureStore(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# Initialize the feature store\u001b[39;00m\n\u001b[1;32m      8\u001b[0m feature_service \u001b[39m=\u001b[39m feature_store\u001b[39m.\u001b[39mget_feature_service(\u001b[39m\"\u001b[39m\u001b[39mdriver_activity_v1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m feature_vector \u001b[39m=\u001b[39m feature_store\u001b[39m.\u001b[39;49mget_online_features(\n\u001b[1;32m     10\u001b[0m     features\u001b[39m=\u001b[39;49mfeature_service,\n\u001b[1;32m     11\u001b[0m     entity_rows\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     12\u001b[0m         \u001b[39m# {join_key: entity_value}\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mdriver_id\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m1004\u001b[39;49m},\n\u001b[1;32m     14\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mdriver_id\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m1005\u001b[39;49m},\n\u001b[1;32m     15\u001b[0m     ],\n\u001b[1;32m     16\u001b[0m )\u001b[39m.\u001b[39mto_dict()\n\u001b[1;32m     18\u001b[0m pprint(feature_vector)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/dt-feast-py3-11-3/lib/python3.11/site-packages/feast/usage.py:299\u001b[0m, in \u001b[0;36mlog_exceptions_and_usage.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     ctx\u001b[39m.\u001b[39mtraceback \u001b[39m=\u001b[39m _trace_to_log(traceback)\n\u001b[1;32m    298\u001b[0m     \u001b[39mif\u001b[39;00m traceback:\n\u001b[0;32m--> 299\u001b[0m         \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(traceback)\n\u001b[1;32m    301\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    302\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/dt-feast-py3-11-3/lib/python3.11/site-packages/feast/usage.py:288\u001b[0m, in \u001b[0;36mlog_exceptions_and_usage.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m ctx\u001b[39m.\u001b[39mattributes\u001b[39m.\u001b[39mupdate(attrs)\n\u001b[1;32m    287\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     \u001b[39mif\u001b[39;00m ctx\u001b[39m.\u001b[39mexception:\n\u001b[1;32m    291\u001b[0m         \u001b[39m# exception was already recorded\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/dt-feast-py3-11-3/lib/python3.11/site-packages/feast/feature_store.py:1583\u001b[0m, in \u001b[0;36mFeatureStore.get_online_features\u001b[0;34m(self, features, entity_rows, full_feature_names)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1581\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll entity_rows must have the same keys.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m-> 1583\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_online_features(\n\u001b[1;32m   1584\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   1585\u001b[0m     entity_values\u001b[39m=\u001b[39;49mcolumnar,\n\u001b[1;32m   1586\u001b[0m     full_feature_names\u001b[39m=\u001b[39;49mfull_feature_names,\n\u001b[1;32m   1587\u001b[0m     native_entity_values\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1588\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/dt-feast-py3-11-3/lib/python3.11/site-packages/feast/feature_store.py:1703\u001b[0m, in \u001b[0;36mFeatureStore._get_online_features\u001b[0;34m(self, features, entity_values, full_feature_names, native_entity_values)\u001b[0m\n\u001b[1;32m   1700\u001b[0m         requested_result_row_names\u001b[39m.\u001b[39madd(join_key)\n\u001b[1;32m   1701\u001b[0m         join_key_values[join_key] \u001b[39m=\u001b[39m values\n\u001b[0;32m-> 1703\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mensure_request_data_values_exist(\n\u001b[1;32m   1704\u001b[0m     needed_request_data, needed_request_fv_features, request_data_features\n\u001b[1;32m   1705\u001b[0m )\n\u001b[1;32m   1707\u001b[0m \u001b[39m# Populate online features response proto with join keys and request data features\u001b[39;00m\n\u001b[1;32m   1708\u001b[0m online_features_response \u001b[39m=\u001b[39m GetOnlineFeaturesResponse(results\u001b[39m=\u001b[39m[])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/dt-feast-py3-11-3/lib/python3.11/site-packages/feast/feature_store.py:1891\u001b[0m, in \u001b[0;36mFeatureStore.ensure_request_data_values_exist\u001b[0;34m(needed_request_data, needed_request_fv_features, request_data_features)\u001b[0m\n\u001b[1;32m   1881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(needed_request_data) \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(needed_request_fv_features) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\n\u001b[1;32m   1882\u001b[0m     request_data_features\u001b[39m.\u001b[39mkeys()\n\u001b[1;32m   1883\u001b[0m ):\n\u001b[1;32m   1884\u001b[0m     missing_features \u001b[39m=\u001b[39m [\n\u001b[1;32m   1885\u001b[0m         x\n\u001b[1;32m   1886\u001b[0m         \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[39mif\u001b[39;00m x \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m request_data_features\n\u001b[1;32m   1890\u001b[0m     ]\n\u001b[0;32m-> 1891\u001b[0m     \u001b[39mraise\u001b[39;00m RequestDataNotFoundInEntityRowsException(\n\u001b[1;32m   1892\u001b[0m         feature_names\u001b[39m=\u001b[39mmissing_features\n\u001b[1;32m   1893\u001b[0m     )\n",
      "\u001b[0;31mRequestDataNotFoundInEntityRowsException\u001b[0m: Required request data source features ['val_to_add', 'val_to_add_2'] not found in the entity rows, but required by feature views"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from feast import FeatureStore\n",
    "\n",
    "\n",
    "feature_store = FeatureStore('.')  # Initialize the feature store\n",
    "\n",
    "\n",
    "feature_service = feature_store.get_feature_service(\"driver_activity_v1\")\n",
    "feature_vector = feature_store.get_online_features(\n",
    "    features=feature_service,\n",
    "    entity_rows=[\n",
    "        # {join_key: entity_value}\n",
    "        {\"driver_id\": 1004},\n",
    "        {\"driver_id\": 1005},\n",
    "    ],\n",
    ").to_dict()\n",
    "\n",
    "pprint(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FeatureService(name = driver_activity_v1, _features = [], feature_view_projections = [FeatureViewProjection(name='driver_hourly_stats', name_alias='', desired_features=[], features=[conv_rate-Float32], join_key_map={}), FeatureViewProjection(name='transformed_conv_rate', name_alias='', desired_features=[], features=[conv_rate_plus_val1-Float64, conv_rate_plus_val2-Float64], join_key_map={})], description = , tags = {}, owner = , created_timestamp = 2023-04-15 06:06:10.707176, last_updated_timestamp = 2023-04-15 06:06:10.707176, logging_config = None)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dt-feast-py3-11-3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
